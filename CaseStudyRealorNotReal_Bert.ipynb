{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CaseStudyRealorNotReal_Bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZS8QJ_bJs28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import all dependencies\n",
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JsoM8pZHxq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "5a21b457-e610-4dc8-8272-b20e1659a8d1"
      },
      "source": [
        "#download bert packages\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/5c/6439134ecd17b33fe0396fb0b7d6ce3c5a120c42a4516ba0e9a2d6e43b25/bert-for-tf2-0.14.4.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 28.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 2.7MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.4-cp36-none-any.whl size=30114 sha256=f2e7f5d37d13219020dae0d53e5de435307e7f04a8561a3521e0d0f7efc19c21\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/3f/4d/79d7735015a5f523648df90d871ce8e89a7df8185f7703eeab\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=5910fa0f9c1572a80f4bb68d04dbf96d95fd7afb4c107f908f847b1f0fead2d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19473 sha256=5b72e6f0e8589650737064f64e12e5a48615a4162730354212eae38a33dec27d\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.4 params-flow-0.8.2 py-params-0.9.7\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_BdbG_pI9Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_SC728dnl6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "afe68a55-30e1-443f-f55e-b1e95f17811c"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout, Input\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, LSTM, GRU, SimpleRNN\n",
        "from keras.initializers import Constant\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtMYK5UgKKCW",
        "colab_type": "text"
      },
      "source": [
        "# loading files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vgXsUaAJ1ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "ec8f1b5c-6120-4221-9724-f534e4cf32a0"
      },
      "source": [
        "#get data from personal google drive folders\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8eZzQ9qLLuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/twitterfakenews/train.csv\", engine=\"python\", encoding = \"latin1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2Kl8dg88MJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv(\"/content/drive/My Drive/twitterfakenews/test.csv\", engine=\"python\", encoding = \"latin1\")"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA_tf1w9MExU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "c0b517b2-da8f-416e-ae8a-8a1237af69f3"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c75ik_73KJKu",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1mgrYoUMXBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop([\"keyword\", \"location\", \"id\"], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GHCyT5D8VLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.drop([\"keyword\", \"location\"], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6GozzB-MgJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "2a6f5070-5e2f-474b-b1e1-4e854f39cd0c"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  Our Deeds are the Reason of this #earthquake M...       1\n",
              "1             Forest fire near La Ronge Sask. Canada       1\n",
              "2  All residents asked to 'shelter in place' are ...       1\n",
              "3  13,000 people receive #wildfires evacuation or...       1\n",
              "4  Just got sent this photo from Ruby #Alaska as ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we_owLpuMyoX",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIIWUX8fMm4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clean tweet\n",
        "def clean_tweet(tweet):\n",
        "  tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "  tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet) #remove mentions\n",
        "  tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "  tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "  tweet = re.sub(r\" +\", ' ', tweet)\n",
        "  tweet = tweet.lower()\n",
        "  return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jphsmBGzOITv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clean = [clean_tweet(tweet) for tweet in data.text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXX-m93iO37v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_labels = data.target.values #get in numpy format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPHd5-RI8iNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_clean = [clean_tweet(tweet) for tweet in test.text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPMCDcrdO1Ck",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la63tr5DOr-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Fulltokenizer = bert.bert_tokenization.FullTokenizer\n",
        "#bert layer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_zh_L-12_H-768_A-12/1\", trainable = False)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = Fulltokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEUNTPU4M0Jz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "edc390d1-2888-427d-c2a0-cf85443d1398"
      },
      "source": [
        "tokenizer.tokenize(\"Samantha loves final fantasy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[UNK]', 'love', '##s', 'final', 'fantasy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K17p2KPIM9bx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e3cb7d56-09a6-41bc-ee3b-db6155d396ab"
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"Samantha loves final fantasy\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[100, 8451, 8118, 10591, 12436]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1mGuJZSNP0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_sentence(sent):\n",
        "  return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkAxtXrKNuqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_inputs = [encode_sentence(sent) for sent in data_clean]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6bH2L7kOLxh",
        "colab_type": "text"
      },
      "source": [
        "# Dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5T1P1BRN9fa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#padding tokens per batch all the sentences do not need to have the same length\n",
        "data_with_len = [[sent, data_labels[i], len(sent)]\n",
        "                 for i, sent in enumerate(data_inputs)]\n",
        "#random.shuffle(data_with_len) #not always necessary\n",
        "data_with_len.sort(key = lambda x: x[2]) #sort based on length get access to the third element\n",
        "sorted_all = [(sent_lab[0], sent_lab[1])\n",
        "              for sent_lab in data_with_len] #remove short sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7GMM_A-erqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all, output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loZueNqcCgsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_test = tf.data.Dataset.from_generator(lambda: test_inputs, output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2prJMueI34Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c5b1a8d0-4aad-4b72-a2fc-98c5b7d45ccb"
      },
      "source": [
        "next(iter(all_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10353,  9558], dtype=int32)>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "094r1uOW2Eio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kb2HaUg4Zs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NB_BATCHES =math.ceil(len(sorted_all)/BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXSUmfy85cNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "43799911-863e-4c3e-9e82-e0f0b06c25ab"
      },
      "source": [
        "NB_BATCHES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "238"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQiKVgkvNdGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "b177d2cd-f80c-4723-b381-2085b15a1476"
      },
      "source": [
        "next(iter(all_batched))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 4), dtype=int32, numpy=\n",
              " array([[10353,  9558,     0,     0],\n",
              "        [ 8811, 10841,     0,     0],\n",
              "        [ 8413, 10447,     0,     0],\n",
              "        [12139,  8542,     0,     0],\n",
              "        [10451,  8180,     0,     0],\n",
              "        [ 9193,  8451,     0,     0],\n",
              "        [ 9978,  8310, 11338,     0],\n",
              "        [ 8792,  8902,  8798,     0],\n",
              "        [ 8174,  9931,   106,     0],\n",
              "        [10100,  8613,  9069,     0],\n",
              "        [10100,  8613,  9069,     0],\n",
              "        [ 9867, 13214,  8118,     0],\n",
              "        [13158,  8197,   163,     0],\n",
              "        [10951, 12670,  8303,     0],\n",
              "        [ 8363, 11486,  8118,     0],\n",
              "        [ 8363, 11486,  8118,     0],\n",
              "        [10092,  8179, 11229,     0],\n",
              "        [12289,  9917,  8863,     0],\n",
              "        [12289,  9917,  8863,     0],\n",
              "        [12289,  9917,  8863,     0],\n",
              "        [12605,  8458,  8487,     0],\n",
              "        [  151, 10235, 11229,     0],\n",
              "        [ 8450,  9238, 11140,     0],\n",
              "        [11515, 11714,  8221,     0],\n",
              "        [11515, 11714,  8221,     0],\n",
              "        [11515, 11714,  8221,     0],\n",
              "        [11515, 11714,  8221,     0],\n",
              "        [11515, 11714,  8118,     0],\n",
              "        [11515, 11714,  8118,     0],\n",
              "        [11515, 11714,  8118,     0],\n",
              "        [11515, 11714,  8118,     0],\n",
              "        [10366,  8310,  8451,  8436]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWqXLXIc5eMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NB_BATCHES_TEST = NB_BATCHES //10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81t7PED76tBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_batched.shuffle(NB_BATCHES)\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gFCSp_z7ctM",
        "colab_type": "text"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKfP6YFj7bBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, vocab_size,\n",
        "               emb_dim = 128,\n",
        "               LSTM_units = 50,\n",
        "               dropout_rate = 0.1,\n",
        "               training = False,\n",
        "               name = \"lstm\"):\n",
        "    super(LSTM, self).__init__(name=name)\n",
        "\n",
        "    self.embedding = layers.Embedding(vocab_size, emb_dim)\n",
        "    self.dense_1 = layers.Bidirectional(layers.LSTM(LSTM_units, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "    self.pool = layers.GlobalAveragePooling1D()\n",
        "    self.dropout = layers.Dropout(rate =dropout_rate)\n",
        "    self.last_dense = layers.Dense(units =1, activation= \"sigmoid\")\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    x = self.embedding(inputs)\n",
        "    x_1 = self.dense_1(x)\n",
        "    x_2 = self.pool(x_1)\n",
        "    x_3 = self.dropout(x_2)\n",
        "    output = self.last_dense(x_3)\n",
        "\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DerjH6AqE9yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "LSTM_UNITS = 50\n",
        "NB_CLASSES = 2\n",
        "DROPOUT_RATE = 0.1\n",
        "NB_EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifYmWZ3OFnrA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "3a1b4ac8-b3b2-4d75-eeb3-c1f56201af3b"
      },
      "source": [
        "lstm = LSTM(vocab_size= VOCAB_SIZE,\n",
        "            emb_dim = EMB_DIM,\n",
        "            LSTM_units = LSTM_UNITS,\n",
        "            dropout_rate = DROPOUT_RATE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "topktLy3F7dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dcnn.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjTIHn0fHL5w",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6H2ZRYiHNOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm.fit(train_dataset, epochs = NB_EPOCHS, validation_split = .1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_JnJSFP8r2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_prediction(sent):\n",
        "  tokens = encode_sentence(sent)\n",
        "  inputs = tf.expand_dims(tokens, 0)\n",
        "\n",
        "  output = Dcnn(inputs, training = False)\n",
        "\n",
        "  target = math.floor(output*2)\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px1u3sOK4XuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fb57c0b8-140c-4250-def4-9760a1497e51"
      },
      "source": [
        "range(len(preds))"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvW2mLfy_yCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = [get_prediction(sent) for sent in test_clean]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efWtdSQH4cef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "cc7e6e92-9a10-45b5-8f2c-dd7e5af07e18"
      },
      "source": [
        "y_preds = []\n",
        "for i in range(len(preds)): \n",
        "  y_hat = preds[i].numpy()\n",
        "  y_preds.append(y_hat)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.9999869]], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSJF6X5M6x8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = np.stack(y_preds, axis=0)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXTM0URs7FkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.matrix(y_hat)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zock8ath78yO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = pd.DataFrame(y_pred)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2R_2gFB8Kmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = pred.T"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAv7ix6Q3h8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = pd.DataFrame(test[['id']])\n",
        "df = pd.concat([ids, pred], axis = 1)\n",
        "df.columns = ['id', 'target']\n",
        "df.set_index('id', inplace=True)"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHY-F8ak8YSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['target'] = df['target'].apply(lambda x: 0 if x < .5 else 1)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni2iOdga8jsc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "e6a3cc10-b634-41dd-93e6-5ae4c42df33f"
      },
      "source": [
        "df.head"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of        target\n",
              "id           \n",
              "0           1\n",
              "2           1\n",
              "3           1\n",
              "9           1\n",
              "11          1\n",
              "...       ...\n",
              "10861       1\n",
              "10865       1\n",
              "10868       1\n",
              "10874       1\n",
              "10875       1\n",
              "\n",
              "[3263 rows x 1 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFvxbe0X8dCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save\n",
        "df.to_csv(\"/content/drive/My Drive/twitterfakenews/mysubmissio_bert.csv\")"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMkoAAj79KSz",
        "colab_type": "text"
      },
      "source": [
        "scores 0.74961 which is not bad"
      ]
    }
  ]
}